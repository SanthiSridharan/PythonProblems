Problem 0: Two algorithms to calculate sample variance
This problem is related to floating-point arithmetic and the sample variance, a commonly used measure in statistics. However, the problem should go quickly -- so, if you find yourself spending a lot of time on it, you may be overthinking it or consider returning to it later.

There are two exercises, numbered 0 and 1, which are worth a total of ten (10) points.

Setup
Python has a built-in function, statistics.variance, that computes the sample variance. However, for this problem we want you to implement it from scratch in two different ways and compare their accuracy. (The test codes will use Python's function as a baseline for comparison against your implementations.)

# Run this cell.
from statistics import variance

SAVE_VARIANCE = variance # Ignore me
A baseline algorithm to compute the sample variance
Suppose we observe  n  samples from a much larger population. Denote these observations by  x0,x1,…,xn−1 . Then the sample mean (sample average),  x¯ , is defined to be

x¯≡1n∑i=0n−1xi.
 
Given both the samples and the sample mean, a standard formula for the (unbiased) sample variance,  s¯2 , is

s¯2≡1n−1∑i=0n−1(xi−x¯)2.
 
Exercise 0 (5 points). Write a function, var_method_0(x), that implements this formula for the sample variance given a list x[:] of observed sample values.

Remember not to use Python's built-in variance().

def var_method_0(x):
   meanval = 0.0
   ntot = len(x)
   # for x_i in x:
   #     x_i += x_i
   # meanval = accurate_sum(x)/ntot
   # variance = accurate_sum([abs((x_i-meanval))**2 for x_i in x])/ntot
   # meanval = sum([i for i in x])/ ntot
   # calculate mean
   m = sum(x) / len(x)
   print("Mean", m)
   # calculate variance using a list comprehension
   var_res = sum((xi - m) ** 2 for xi in x) / len(x)
   # meanval = statistics.mean(x)
   # print("MeanVal",meanval)
   # variance = accurate_sum([(Decimal(x_i)-meanval)**2 for x_i in x])/ntot
   print(var_res)

   return float(var_res)

from random import gauss

n = 100000
mu = 1e7  # True mean
sigma = 100.0  # True variance

for _ in range(5): # 5 trials
    X = [gauss(mu, sigma) for _ in range(n)]
    var_py = variance(X)
    try:
        del variance
        var_you_0 = var_method_0(X)
    except NameError as n:
        if n.args[0] == "name 'variance' is not defined":
            assert False, "Did you try to use `variance()` instead of implementing it from scratch?"
        else:
            raise n
    finally:
        variance = SAVE_VARIANCE
        
    rel_diff = abs(var_you_0 - var_py) / var_py
    print("\nData: n={} samples from a Gaussian with mean {} and standard deviation {}".format(n, mu, sigma))
    print("\tPython's variance function computed {}.".format(var_py))
    print("\tYour var_method_0(X) computed {}.".format(var_you_0))
    print("\tThe relative difference is |you - python| / |python| ~= {}.".format(rel_diff))
    assert rel_diff <= n*(2.0**(-52)), "Relative difference is larger than expected..."
    
print("\n(Passed!)")
Data: n=100000 samples from a Gaussian with mean 10000000.0 and standard deviation 100.0
	Python's variance function computed 9997.340998811474.
	Your var_method_0(X) computed 1000000002388.2118.
	The relative difference is |you - python| / |python| ~= 100026596.32293777.
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-5-84f4b6082984> in <module>
     26     print("\tYour var_method_0(X) computed {}.".format(var_you_0))
     27     print("\tThe relative difference is |you - python| / |python| ~= {}.".format(rel_diff))
---> 28     assert rel_diff <= n*(2.0**(-52)), "Relative difference is larger than expected..."
     29 
     30 print("\n(Passed!)")

AssertionError: Relative difference is larger than expected...
A one-pass algorithm
If there are a huge number of samples, the preceding formula can be slow. The reason is that it makes two passes (or loops) over the data: once to sum the samples and another to sum the squares of the samples.

So if there are a huge number of samples and these were stored on disk, for instance, you would have to read each sample from disk twice. (For reference, the cost of accessing data on disk can be orders of magnitude slower than reading it from memory.)

However, there is an alternative that would touch each observation only once. It is based on this formula:

s¯2=(∑n−1i=0x2i)−1n(∑n−1i=0xi)2n−1.
 
In exact arithmetic, it is the same as the previous formula. And it can be implemented using only one pass of the data, using an algorithm of the following form:

  temp_sum = 0
  temp_sum_squares = 0
  for each observation x_i: # Read x_i once, but use twice!
     temp_sum += x_i
     temp_sum_squares += (x_i * x_i)
  (calculate final variance)
But there is a catch, related to the numerical stability of this scheme.

Exercise 1 (5 points). Implement a function, var_method_1(x), for the one-pass scheme shown above.

The test cell below will run several experiments comparing its accuracy to the accuracy of the first method. You should observe that the one-pass method can be highly inaccurate!

def var_method_1(x):
    n = len(x)
    ###
    ### YOUR CODE HERE
    ###
# Test cell: `exercise_1_test`

from random import gauss
from statistics import variance

n = 100000
mu = 1e7
sigma = 1.0

for _ in range(5): # 5 trials
    X = [gauss(mu, sigma) for _ in range(n)]
    var_py = variance(X)
    try:
        del variance
        var_you_0 = var_method_0(X)
        var_you_1 = var_method_1(X)
    except NameError as n:
        if n.args[0] == "name 'variance' is not defined":
            assert False, "Did you try to use `variance()` instead of implementing it from scratch?"
        else:
            raise n
    finally:
        variance = SAVE_VARIANCE
        
    rel_diff_0 = abs(var_you_0 - var_py) / var_py
    rel_diff_1 = abs(var_you_1 - var_py) / var_py
    print("\nData: n={} samples from a Gaussian with mean {} and standard deviation {}".format(n, mu, sigma))
    print("\tPython's variance function computed {}.".format(var_py))
    print("\tvar_method_0(X) computed {}, with a relative difference of {}.".format(var_you_0, rel_diff_0))
    assert rel_diff_0 <= n*(2.0**(-52)), "The relative difference is larger than expected."
    print("\tvar_method_1(X) computed {}, with a relative difference of {}.".format(var_you_1, rel_diff_1))
    assert rel_diff_1 > n*(2.0**(-52)), "The relative difference is smaller than expected!"
    
print("\n(Passed!)")
Fin! If you've reached this point and all tests above pass, you are ready to submit your solution to this problem. Don't forget to save you work prior to submitting.
